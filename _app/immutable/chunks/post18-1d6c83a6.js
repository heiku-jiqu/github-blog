import{S as mt,i as ut,s as ht,k as r,q as n,a as c,l,m as s,r as p,h as t,c as f,n as h,b as o,B as a,A as qe}from"./index-39c5cc75.js";function dt(ft){let d,le,Q,C,se,U,P,pe,j,R,ce,z,x,fe,J,F,me,O,H,ue,V,T,he,W,A,de,X,K,be,Y,b,we,D,ye,ve,Z,I,ke,$,S,_e,g,B,Ee,ee,N,Ce,te,G,Pe,ie,L,Re,oe,M,xe,ae,q,Fe,re,m,w,He,Te,y,Ae,Ke,v,Ie,Se,k,Be,Ne,_,Ge,Le,E,Me;return{c(){d=r("h1"),le=n(ct),Q=c(),C=r("h2"),se=n("Introduction"),U=c(),P=r("p"),pe=n("This article summarises some basic considerations on how to choose the number of partitions in a Kafka Topic and the replication factor of the Topic."),j=c(),R=r("p"),ce=n(`TL;DR:
Usually bottlenecked by Consumer processing time.`),z=c(),x=r("p"),fe=n("Throughput: ((processing time for one message in seconds x number of msgs per second) / num of partitions) << 1"),J=c(),F=r("p"),me=n("Latency: number of partitions < 100 x replication factor"),O=c(),H=r("h2"),ue=n("Partition Number"),V=c(),T=r("h3"),he=n("Concepts"),W=c(),A=r("p"),de=n(`Number of partitions also improves write through put in producer and broker side, because writes can be done in parallel.
But writes are already very high throughput, so usually it is not a problem.`),X=c(),K=r("p"),be=n(`Number of partitions determine the maximum number of parallel consumers that can consume the topic.
If topic only has 2 partitions, then only maximum of 2 consumers within a consumer group can read the partition (the rest will stay idle).`),Y=c(),b=r("p"),we=n(`High concentration of partitions to brokers ratio will increase latency, because replication by follower is done on single thread, and consumers can only see messages when it has been commited (replicated > min in sync replicas).
Replicating 1000 partitions from one broker to another can add about 20 ms latency, which implies that the end-to-end latency is `),D=r("em"),ye=n("at least"),ve=n(` 20 ms.
But increasing`),Z=c(),I=r("h2"),ke=n("Replication Factor"),$=c(),S=r("h3"),_e=n("Concepts"),g=c(),B=r("p"),Ee=n(`Partitions within a topic are replicated to other broker nodes. Each partition will have a partition leader, and the rest are partition followers.
Replication Factor determines how many broker nodes have a copy of the partition.
For example, a Replication Factor of 3 means that there will be 1 broker who is assigned the partition leader, and there will be 2 other brokers who are following the writes of the partition leader.`),ee=c(),N=r("h2"),Ce=n("Min in sync replicas"),te=c(),G=r("p"),Pe=n("A write to a Kafka partition is not considered committed until all in-sync replicas have received the write."),ie=c(),L=r("p"),Re=n("Consumers receive only committed messages (i.e. only receive messages that has been successfully received by all in-sync replicas), and will never see a message that could be lost."),oe=c(),M=r("p"),xe=n("Since Consumers can only see messages after all in-sync replicas have received, it means added in sync replicas worsens latency (and availability because writes will fail if not enough online ISRs), but improves durability."),ae=c(),q=r("h2"),Fe=n("Resources"),re=c(),m=r("p"),w=r("a"),He=n("Conduktor Guide on Partition Count and Replication Factor"),Te=c(),y=r("a"),Ae=n("Confluent Guide on Partition Count"),Ke=c(),v=r("a"),Ie=n("Stackoverflow Question on Partition Count"),Se=c(),k=r("a"),Be=n("LinkedIn Engineering on Kafka Benchmark"),Ne=c(),_=r("a"),Ge=n("Confluent Kafka Performance"),Le=c(),E=r("a"),Me=n("Confluent Replication Committed Message Guarantees"),this.h()},l(e){d=l(e,"H1",{});var i=s(d);le=p(i,ct),i.forEach(t),Q=f(e),C=l(e,"H2",{});var De=s(C);se=p(De,"Introduction"),De.forEach(t),U=f(e),P=l(e,"P",{});var Qe=s(P);pe=p(Qe,"This article summarises some basic considerations on how to choose the number of partitions in a Kafka Topic and the replication factor of the Topic."),Qe.forEach(t),j=f(e),R=l(e,"P",{});var Ue=s(R);ce=p(Ue,`TL;DR:
Usually bottlenecked by Consumer processing time.`),Ue.forEach(t),z=f(e),x=l(e,"P",{});var je=s(x);fe=p(je,"Throughput: ((processing time for one message in seconds x number of msgs per second) / num of partitions) << 1"),je.forEach(t),J=f(e),F=l(e,"P",{});var ze=s(F);me=p(ze,"Latency: number of partitions < 100 x replication factor"),ze.forEach(t),O=f(e),H=l(e,"H2",{});var Je=s(H);ue=p(Je,"Partition Number"),Je.forEach(t),V=f(e),T=l(e,"H3",{});var Oe=s(T);he=p(Oe,"Concepts"),Oe.forEach(t),W=f(e),A=l(e,"P",{});var Ve=s(A);de=p(Ve,`Number of partitions also improves write through put in producer and broker side, because writes can be done in parallel.
But writes are already very high throughput, so usually it is not a problem.`),Ve.forEach(t),X=f(e),K=l(e,"P",{});var We=s(K);be=p(We,`Number of partitions determine the maximum number of parallel consumers that can consume the topic.
If topic only has 2 partitions, then only maximum of 2 consumers within a consumer group can read the partition (the rest will stay idle).`),We.forEach(t),Y=f(e),b=l(e,"P",{});var ne=s(b);we=p(ne,`High concentration of partitions to brokers ratio will increase latency, because replication by follower is done on single thread, and consumers can only see messages when it has been commited (replicated > min in sync replicas).
Replicating 1000 partitions from one broker to another can add about 20 ms latency, which implies that the end-to-end latency is `),D=l(ne,"EM",{});var Xe=s(D);ye=p(Xe,"at least"),Xe.forEach(t),ve=p(ne,` 20 ms.
But increasing`),ne.forEach(t),Z=f(e),I=l(e,"H2",{});var Ye=s(I);ke=p(Ye,"Replication Factor"),Ye.forEach(t),$=f(e),S=l(e,"H3",{});var Ze=s(S);_e=p(Ze,"Concepts"),Ze.forEach(t),g=f(e),B=l(e,"P",{});var $e=s(B);Ee=p($e,`Partitions within a topic are replicated to other broker nodes. Each partition will have a partition leader, and the rest are partition followers.
Replication Factor determines how many broker nodes have a copy of the partition.
For example, a Replication Factor of 3 means that there will be 1 broker who is assigned the partition leader, and there will be 2 other brokers who are following the writes of the partition leader.`),$e.forEach(t),ee=f(e),N=l(e,"H2",{});var ge=s(N);Ce=p(ge,"Min in sync replicas"),ge.forEach(t),te=f(e),G=l(e,"P",{});var et=s(G);Pe=p(et,"A write to a Kafka partition is not considered committed until all in-sync replicas have received the write."),et.forEach(t),ie=f(e),L=l(e,"P",{});var tt=s(L);Re=p(tt,"Consumers receive only committed messages (i.e. only receive messages that has been successfully received by all in-sync replicas), and will never see a message that could be lost."),tt.forEach(t),oe=f(e),M=l(e,"P",{});var it=s(M);xe=p(it,"Since Consumers can only see messages after all in-sync replicas have received, it means added in sync replicas worsens latency (and availability because writes will fail if not enough online ISRs), but improves durability."),it.forEach(t),ae=f(e),q=l(e,"H2",{});var ot=s(q);Fe=p(ot,"Resources"),ot.forEach(t),re=f(e),m=l(e,"P",{});var u=s(m);w=l(u,"A",{href:!0,rel:!0});var at=s(w);He=p(at,"Conduktor Guide on Partition Count and Replication Factor"),at.forEach(t),Te=f(u),y=l(u,"A",{href:!0,rel:!0});var rt=s(y);Ae=p(rt,"Confluent Guide on Partition Count"),rt.forEach(t),Ke=f(u),v=l(u,"A",{href:!0,rel:!0});var nt=s(v);Ie=p(nt,"Stackoverflow Question on Partition Count"),nt.forEach(t),Se=f(u),k=l(u,"A",{href:!0,rel:!0});var lt=s(k);Be=p(lt,"LinkedIn Engineering on Kafka Benchmark"),lt.forEach(t),Ne=f(u),_=l(u,"A",{href:!0,rel:!0});var st=s(_);Ge=p(st,"Confluent Kafka Performance"),st.forEach(t),Le=f(u),E=l(u,"A",{href:!0,rel:!0});var pt=s(E);Me=p(pt,"Confluent Replication Committed Message Guarantees"),pt.forEach(t),u.forEach(t),this.h()},h(){h(w,"href","https://www.conduktor.io/kafka/kafka-topics-choosing-the-replication-factor-and-partitions-count/"),h(w,"rel","nofollow"),h(y,"href","https://www.confluent.io/blog/how-choose-number-topics-partitions-kafka-cluster/"),h(y,"rel","nofollow"),h(v,"href","https://stackoverflow.com/questions/50271677/how-to-choose-the-no-of-partitions-for-a-kafka-topic"),h(v,"rel","nofollow"),h(k,"href","https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines"),h(k,"rel","nofollow"),h(_,"href","https://developer.confluent.io/learn/kafka-performance/"),h(_,"rel","nofollow"),h(E,"href","https://docs.confluent.io/kafka/design/replication.html"),h(E,"rel","nofollow")},m(e,i){o(e,d,i),a(d,le),o(e,Q,i),o(e,C,i),a(C,se),o(e,U,i),o(e,P,i),a(P,pe),o(e,j,i),o(e,R,i),a(R,ce),o(e,z,i),o(e,x,i),a(x,fe),o(e,J,i),o(e,F,i),a(F,me),o(e,O,i),o(e,H,i),a(H,ue),o(e,V,i),o(e,T,i),a(T,he),o(e,W,i),o(e,A,i),a(A,de),o(e,X,i),o(e,K,i),a(K,be),o(e,Y,i),o(e,b,i),a(b,we),a(b,D),a(D,ye),a(b,ve),o(e,Z,i),o(e,I,i),a(I,ke),o(e,$,i),o(e,S,i),a(S,_e),o(e,g,i),o(e,B,i),a(B,Ee),o(e,ee,i),o(e,N,i),a(N,Ce),o(e,te,i),o(e,G,i),a(G,Pe),o(e,ie,i),o(e,L,i),a(L,Re),o(e,oe,i),o(e,M,i),a(M,xe),o(e,ae,i),o(e,q,i),a(q,Fe),o(e,re,i),o(e,m,i),a(m,w),a(w,He),a(m,Te),a(m,y),a(y,Ae),a(m,Ke),a(m,v),a(v,Ie),a(m,Se),a(m,k),a(k,Be),a(m,Ne),a(m,_),a(_,Ge),a(m,Le),a(m,E),a(E,Me)},p:qe,i:qe,o:qe,d(e){e&&t(d),e&&t(Q),e&&t(C),e&&t(U),e&&t(P),e&&t(j),e&&t(R),e&&t(z),e&&t(x),e&&t(J),e&&t(F),e&&t(O),e&&t(H),e&&t(V),e&&t(T),e&&t(W),e&&t(A),e&&t(X),e&&t(K),e&&t(Y),e&&t(b),e&&t(Z),e&&t(I),e&&t($),e&&t(S),e&&t(g),e&&t(B),e&&t(ee),e&&t(N),e&&t(te),e&&t(G),e&&t(ie),e&&t(L),e&&t(oe),e&&t(M),e&&t(ae),e&&t(q),e&&t(re),e&&t(m)}}}const bt={title:"Choosing Kafka Partition Number and Replication Factor",date:"2023-11-16"},{title:ct,date:yt}=bt;class vt extends mt{constructor(d){super(),ut(this,d,null,dt,ht,{})}}export{vt as default,bt as metadata};
