import{S as ol,i as al,s as nl,k as n,q as o,a as p,l,m as c,r as a,h as s,c as u,n as Sa,b as i,B as e,A as Ra}from"./index-4cbca6b4.js";function ll(Xn){let T,es,_t,g,ts,ke,ss,os,bt,Q,as,yt,V,ns,Ct,d,W,he,ls,cs,rs,X,me,is,ps,us,Y,ve,fs,ds,ks,z,Ee,hs,ms,_e,vs,Es,_s,Z,be,bs,ys,wt,$,Cs,Pt,S,ws,ye,Ps,Os,Ot,k,Ce,Ds,Ls,we,Is,Ks,Pe,Ts,gs,Oe,zs,Ss,De,Rs,Dt,ee,qs,Lt,M,Le,Hs,xs,It,A,Yn='<code class="language-py">producer <span class="token operator">=</span> Producer<span class="token punctuation">(</span>config<span class="token punctuation">)</span></code>',Kt,te,Ms,Tt,f,R,Ie,As,Us,Ke,Ns,js,Js,v,Te,Bs,Gs,ge,Fs,Qs,ze,Vs,Ws,Se,Xs,Ys,Zs,b,Re,$s,eo,qe,to,so,He,oo,ao,no,U,xe,lo,co,Me,ro,io,N,Ae,po,uo,Ue,fo,ko,q,ho,Ne,mo,vo,je,Eo,gt,se,_o,zt,L,bo,Je,yo,Co,Be,wo,St,I,Ge,Po,Oo,Fe,Do,Lo,Rt,oe,Io,qt,h,Qe,Ko,To,Ve,go,zo,We,So,Ro,Xe,qo,Ho,Ye,xo,Ht,ae,Mo,xt,j,Zn=`<code class="language-py"><span class="token keyword">from</span> confluent_kafka <span class="token keyword">import</span> Producer

config <span class="token operator">=</span> <span class="token punctuation">&#123;</span>boostrap<span class="token punctuation">.</span>servers<span class="token punctuation">:</span> localhost<span class="token punctuation">:</span><span class="token number">9092</span><span class="token punctuation">&#125;</span>
producer <span class="token operator">=</span> Producer<span class="token punctuation">(</span>config<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">callback</span><span class="token punctuation">(</span>err<span class="token punctuation">:</span> KafkaError<span class="token punctuation">,</span> msg<span class="token punctuation">:</span> Message<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> err<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Event produce to topic </span><span class="token interpolation"><span class="token punctuation">&#123;</span>msg<span class="token punctuation">.</span>topic<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string"> failed for event: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>event<span class="token punctuation">.</span>key<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>msg<span class="token punctuation">.</span>value<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string"> sent to topic </span><span class="token interpolation"><span class="token punctuation">&#123;</span>msg<span class="token punctuation">.</span>topic<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string"> in partition </span><span class="token interpolation"><span class="token punctuation">&#123;</span>msg<span class="token punctuation">.</span>partition<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

producer<span class="token punctuation">.</span>produce<span class="token punctuation">(</span>
    topic <span class="token operator">=</span> <span class="token string">'hello_topic'</span><span class="token punctuation">,</span>
    key <span class="token operator">=</span> <span class="token string">"abc"</span><span class="token punctuation">,</span>
    value <span class="token operator">=</span> <span class="token string">"hello abc"</span><span class="token punctuation">,</span>
    on_delivery <span class="token operator">=</span> callback
<span class="token punctuation">)</span>
producer<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span></code>`,Mt,ne,Ao,At,H,Uo,Ze,No,jo,Ut,m,$e,Jo,Bo,et,Go,Fo,tt,Qo,Vo,st,Wo,Xo,ot,Yo,Nt,le,Zo,jt,ce,$o,Jt,E,re,at,ea,ta,sa,y,nt,oa,aa,lt,na,la,ct,ca,ra,ia,ie,rt,pa,ua,fa,pe,it,da,ka,Bt,ue,ha,Gt,J,pt,ma,va,Ft,C,ut,Ea,_a,ft,ba,ya,dt,Ca,Qt,fe,wa,Vt,B,$n=`<code class="language-py">config
consumer <span class="token operator">=</span> Consumer<span class="token punctuation">(</span>config<span class="token punctuation">)</span>

<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
    event <span class="token operator">=</span> consumer<span class="token punctuation">.</span>poll<span class="token punctuation">(</span>timeout<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> event <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">continue</span>
    <span class="token keyword">if</span> event<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#handle error</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token comment">#process event</span>
        consumer<span class="token punctuation">.</span>commit<span class="token punctuation">(</span>event<span class="token punctuation">)</span></code>`;return{c(){T=n("h1"),es=o(Wn),_t=p(),g=n("p"),ts=o(`Python has multiple client implementations to interact with a Kafka cluster.
This post will walk through the `),ke=n("code"),ss=o("confluent-kafka-python"),os=o(" client, which is the official Python client implementation by Confluent Inc."),bt=p(),Q=n("h2"),as=o("Overview"),yt=p(),V=n("p"),ns=o("This client module has a few main classes that make up the bulk of its API:"),Ct=p(),d=n("ul"),W=n("li"),he=n("code"),ls=o("Producer"),cs=o(": To produce events to the Kafka cluster"),rs=p(),X=n("li"),me=n("code"),is=o("Consumer"),ps=o(": To read events from the Kafka cluster"),us=p(),Y=n("li"),ve=n("code"),fs=o("SchemaRegistryClient"),ds=o(": To get metadata/schemas about the Kafka cluster/topics when you have a Kafka Schema Registry server"),ks=p(),z=n("li"),Ee=n("code"),hs=o("Serializer"),ms=o(" / "),_e=n("code"),vs=o("Deserializer"),Es=o(": To serialize and deserialize messages sent/received from Kafka into/from formats like JSON, Protobuf, Avro, etc."),_s=p(),Z=n("li"),be=n("code"),bs=o("AdminClient"),ys=o(": To manage the Kafka cluster (e.g. creating topics, partitions, etc.)"),wt=p(),$=n("h2"),Cs=o("Producer"),Pt=p(),S=n("p"),ws=o("The "),ye=n("code"),Ps=o("Producer"),Os=o(" class is used to send events to Kafka. It is responsible for:"),Ot=p(),k=n("ul"),Ce=n("li"),Ds=o("Partition assignment of the events"),Ls=p(),we=n("li"),Is=o("Batching events for improved throughput (but added latency)"),Ks=p(),Pe=n("li"),Ts=o("Compression of events and its data"),gs=p(),Oe=n("li"),zs=o("Retries (e.g. due to network errors)"),Ss=p(),De=n("li"),Rs=o("Response callbacks when events are successfully delivered"),Dt=p(),ee=n("h3"),qs=o("using Producer"),Lt=p(),M=n("p"),Le=n("code"),Hs=o("Producer"),xs=o(" can be initialised by passing in a dictionary of configuration settings to the constructor."),It=p(),A=n("pre"),Kt=p(),te=n("p"),Ms=o("The configuration can include the following:"),Tt=p(),f=n("ul"),R=n("li"),Ie=n("code"),As=o("bootstrap.servers"),Us=o(" ("),Ke=n("strong"),Ns=o("required"),js=o("): the URL to the Kafka cluster/brokers"),Js=p(),v=n("li"),Te=n("code"),Bs=o("acks"),Gs=o(": level of acknowledgement required before returning from produce request ("),ge=n("code"),Fs=o("0"),Qs=o(", "),ze=n("code"),Vs=o("1"),Ws=o(", "),Se=n("code"),Xs=o("all"),Ys=o(" for no ack, only lead broker ack, and all broker acks, respectively)"),Zs=p(),b=n("li"),Re=n("code"),$s=o("compression.type"),eo=o(": enables compression of messages (e.g. "),qe=n("code"),to=o("gzip"),so=o(", "),He=n("code"),oo=o("zstd"),ao=o(")"),no=p(),U=n("li"),xe=n("code"),lo=o("batch.size"),co=o(": number of bytes to batch up before sending produce request. Should be adjust with "),Me=n("code"),ro=o("linger.ms"),io=p(),N=n("li"),Ae=n("code"),po=o("linger.ms"),uo=o(": number of milliseconds to wait for batch before sending produce request (i.e. latency). Should be adjusted with "),Ue=n("code"),fo=o("batch.size"),ko=p(),q=n("li"),ho=o("any other connection security settings like "),Ne=n("code"),mo=o("security.protocol"),vo=o(" and "),je=n("code"),Eo=o("ssl.keystore"),gt=p(),se=n("h3"),_o=o("methods"),zt=p(),L=n("p"),bo=o("The 2 most important methods to take not of is "),Je=n("code"),yo=o(".produce()"),Co=o(" and "),Be=n("code"),wo=o(".flush()"),St=p(),I=n("p"),Ge=n("code"),Po=o(".produce()"),Oo=o(" is used to send events to Kafka asynchronously, and "),Fe=n("code"),Do=o(".flush()"),Lo=o(" is used to make sure all produce requests and callbacks are complete."),Rt=p(),oe=n("h4"),Io=o("methods for transactions"),qt=p(),h=n("p"),Qe=n("code"),Ko=o("Producer.init_transactions()"),To=p(),Ve=n("code"),go=o("Producer.begin_transaction()"),zo=p(),We=n("code"),So=o("Producer.commit_transaction()"),Ro=p(),Xe=n("code"),qo=o("Producer.abort_transaction()"),Ho=p(),Ye=n("code"),xo=o("Producer.send_offsets_to_transaction()"),Ht=p(),ae=n("h3"),Mo=o("example code"),xt=p(),j=n("pre"),Mt=p(),ne=n("h2"),Ao=o("Consumer"),At=p(),H=n("p"),Uo=o("The "),Ze=n("code"),No=o("Consumer"),jo=o(" class\u2019 main function used to read events from the Kafka cluster. It is also responsbile several areas like:"),Ut=p(),m=n("ul"),$e=n("li"),Jo=o("Subscribing to Kafka topics"),Bo=p(),et=n("li"),Go=o("Reading from those topics"),Fo=p(),tt=n("li"),Qo=o("Keeping track of successfully read events (by updating commited offset)"),Vo=p(),st=n("li"),Wo=o("Manage offsets of the application"),Xo=p(),ot=n("li"),Yo=o("Joining Consumer Groups (to horizontally scale the consumer app, up to number of partitions of topic)"),Nt=p(),le=n("h3"),Zo=o("configs"),jt=p(),ce=n("p"),$o=o("cluster location, security settings, consumer group settings"),Jt=p(),E=n("ul"),re=n("li"),at=n("code"),ea=o("group.id"),ta=o(": the group id that identifies which consumer belongs to which consumer group (i.e. same group id = same consumer group)"),sa=p(),y=n("li"),nt=n("code"),oa=o("auto.offset.reset"),aa=o(": whether to start reading at the beginning of topic ("),lt=n("code"),na=o("earliest"),la=o("), or only read new events as they arrive ("),ct=n("code"),ca=o("latest"),ra=o("); this only comes into play when there is no offsets in Kafka (e.g. at the start of consumer app or when offset expire)"),ia=p(),ie=n("li"),rt=n("code"),pa=o("enable.auto.commit"),ua=o(": whether to manually commit offsets using our code, or let the client automatically commit"),fa=p(),pe=n("li"),it=n("code"),da=o("isolation.level"),ka=o(": transaction processing, whether to read committed or uncomitted events"),Bt=p(),ue=n("h3"),ha=o("methods"),Gt=p(),J=n("p"),pt=n("code"),ma=o("Consumer.subscribe()"),va=o(": subscribes to Kafka topics. can pass in callbacks to handle on reshuffle etc."),Ft=p(),C=n("p"),ut=n("code"),Ea=o("Consumer.poll()"),_a=o(": returns either "),ft=n("code"),ba=o("None"),ya=o(" or a "),dt=n("code"),Ca=o("Message"),Qt=p(),fe=n("h3"),wa=o("example code"),Vt=p(),B=n("pre"),this.h()},l(t){T=l(t,"H1",{});var r=c(T);es=a(r,Wn),r.forEach(s),_t=u(t),g=l(t,"P",{});var Wt=c(g);ts=a(Wt,`Python has multiple client implementations to interact with a Kafka cluster.
This post will walk through the `),ke=l(Wt,"CODE",{});var qa=c(ke);ss=a(qa,"confluent-kafka-python"),qa.forEach(s),os=a(Wt," client, which is the official Python client implementation by Confluent Inc."),Wt.forEach(s),bt=u(t),Q=l(t,"H2",{});var Ha=c(Q);as=a(Ha,"Overview"),Ha.forEach(s),yt=u(t),V=l(t,"P",{});var xa=c(V);ns=a(xa,"This client module has a few main classes that make up the bulk of its API:"),xa.forEach(s),Ct=u(t),d=l(t,"UL",{});var w=c(d);W=l(w,"LI",{});var Pa=c(W);he=l(Pa,"CODE",{});var Ma=c(he);ls=a(Ma,"Producer"),Ma.forEach(s),cs=a(Pa,": To produce events to the Kafka cluster"),Pa.forEach(s),rs=u(w),X=l(w,"LI",{});var Oa=c(X);me=l(Oa,"CODE",{});var Aa=c(me);is=a(Aa,"Consumer"),Aa.forEach(s),ps=a(Oa,": To read events from the Kafka cluster"),Oa.forEach(s),us=u(w),Y=l(w,"LI",{});var Da=c(Y);ve=l(Da,"CODE",{});var Ua=c(ve);fs=a(Ua,"SchemaRegistryClient"),Ua.forEach(s),ds=a(Da,": To get metadata/schemas about the Kafka cluster/topics when you have a Kafka Schema Registry server"),Da.forEach(s),ks=u(w),z=l(w,"LI",{});var kt=c(z);Ee=l(kt,"CODE",{});var Na=c(Ee);hs=a(Na,"Serializer"),Na.forEach(s),ms=a(kt," / "),_e=l(kt,"CODE",{});var ja=c(_e);vs=a(ja,"Deserializer"),ja.forEach(s),Es=a(kt,": To serialize and deserialize messages sent/received from Kafka into/from formats like JSON, Protobuf, Avro, etc."),kt.forEach(s),_s=u(w),Z=l(w,"LI",{});var La=c(Z);be=l(La,"CODE",{});var Ja=c(be);bs=a(Ja,"AdminClient"),Ja.forEach(s),ys=a(La,": To manage the Kafka cluster (e.g. creating topics, partitions, etc.)"),La.forEach(s),w.forEach(s),wt=u(t),$=l(t,"H2",{});var Ba=c($);Cs=a(Ba,"Producer"),Ba.forEach(s),Pt=u(t),S=l(t,"P",{});var Xt=c(S);ws=a(Xt,"The "),ye=l(Xt,"CODE",{});var Ga=c(ye);Ps=a(Ga,"Producer"),Ga.forEach(s),Os=a(Xt," class is used to send events to Kafka. It is responsible for:"),Xt.forEach(s),Ot=u(t),k=l(t,"UL",{});var P=c(k);Ce=l(P,"LI",{});var Fa=c(Ce);Ds=a(Fa,"Partition assignment of the events"),Fa.forEach(s),Ls=u(P),we=l(P,"LI",{});var Qa=c(we);Is=a(Qa,"Batching events for improved throughput (but added latency)"),Qa.forEach(s),Ks=u(P),Pe=l(P,"LI",{});var Va=c(Pe);Ts=a(Va,"Compression of events and its data"),Va.forEach(s),gs=u(P),Oe=l(P,"LI",{});var Wa=c(Oe);zs=a(Wa,"Retries (e.g. due to network errors)"),Wa.forEach(s),Ss=u(P),De=l(P,"LI",{});var Xa=c(De);Rs=a(Xa,"Response callbacks when events are successfully delivered"),Xa.forEach(s),P.forEach(s),Dt=u(t),ee=l(t,"H3",{});var Ya=c(ee);qs=a(Ya,"using Producer"),Ya.forEach(s),Lt=u(t),M=l(t,"P",{});var Ia=c(M);Le=l(Ia,"CODE",{});var Za=c(Le);Hs=a(Za,"Producer"),Za.forEach(s),xs=a(Ia," can be initialised by passing in a dictionary of configuration settings to the constructor."),Ia.forEach(s),It=u(t),A=l(t,"PRE",{class:!0});var el=c(A);el.forEach(s),Kt=u(t),te=l(t,"P",{});var $a=c(te);Ms=a($a,"The configuration can include the following:"),$a.forEach(s),Tt=u(t),f=l(t,"UL",{});var _=c(f);R=l(_,"LI",{});var ht=c(R);Ie=l(ht,"CODE",{});var en=c(Ie);As=a(en,"bootstrap.servers"),en.forEach(s),Us=a(ht," ("),Ke=l(ht,"STRONG",{});var tn=c(Ke);Ns=a(tn,"required"),tn.forEach(s),js=a(ht,"): the URL to the Kafka cluster/brokers"),ht.forEach(s),Js=u(_),v=l(_,"LI",{});var K=c(v);Te=l(K,"CODE",{});var sn=c(Te);Bs=a(sn,"acks"),sn.forEach(s),Gs=a(K,": level of acknowledgement required before returning from produce request ("),ge=l(K,"CODE",{});var on=c(ge);Fs=a(on,"0"),on.forEach(s),Qs=a(K,", "),ze=l(K,"CODE",{});var an=c(ze);Vs=a(an,"1"),an.forEach(s),Ws=a(K,", "),Se=l(K,"CODE",{});var nn=c(Se);Xs=a(nn,"all"),nn.forEach(s),Ys=a(K," for no ack, only lead broker ack, and all broker acks, respectively)"),K.forEach(s),Zs=u(_),b=l(_,"LI",{});var G=c(b);Re=l(G,"CODE",{});var ln=c(Re);$s=a(ln,"compression.type"),ln.forEach(s),eo=a(G,": enables compression of messages (e.g. "),qe=l(G,"CODE",{});var cn=c(qe);to=a(cn,"gzip"),cn.forEach(s),so=a(G,", "),He=l(G,"CODE",{});var rn=c(He);oo=a(rn,"zstd"),rn.forEach(s),ao=a(G,")"),G.forEach(s),no=u(_),U=l(_,"LI",{});var Yt=c(U);xe=l(Yt,"CODE",{});var pn=c(xe);lo=a(pn,"batch.size"),pn.forEach(s),co=a(Yt,": number of bytes to batch up before sending produce request. Should be adjust with "),Me=l(Yt,"CODE",{});var un=c(Me);ro=a(un,"linger.ms"),un.forEach(s),Yt.forEach(s),io=u(_),N=l(_,"LI",{});var Zt=c(N);Ae=l(Zt,"CODE",{});var fn=c(Ae);po=a(fn,"linger.ms"),fn.forEach(s),uo=a(Zt,": number of milliseconds to wait for batch before sending produce request (i.e. latency). Should be adjusted with "),Ue=l(Zt,"CODE",{});var dn=c(Ue);fo=a(dn,"batch.size"),dn.forEach(s),Zt.forEach(s),ko=u(_),q=l(_,"LI",{});var mt=c(q);ho=a(mt,"any other connection security settings like "),Ne=l(mt,"CODE",{});var kn=c(Ne);mo=a(kn,"security.protocol"),kn.forEach(s),vo=a(mt," and "),je=l(mt,"CODE",{});var hn=c(je);Eo=a(hn,"ssl.keystore"),hn.forEach(s),mt.forEach(s),_.forEach(s),gt=u(t),se=l(t,"H3",{});var mn=c(se);_o=a(mn,"methods"),mn.forEach(s),zt=u(t),L=l(t,"P",{});var vt=c(L);bo=a(vt,"The 2 most important methods to take not of is "),Je=l(vt,"CODE",{});var vn=c(Je);yo=a(vn,".produce()"),vn.forEach(s),Co=a(vt," and "),Be=l(vt,"CODE",{});var En=c(Be);wo=a(En,".flush()"),En.forEach(s),vt.forEach(s),St=u(t),I=l(t,"P",{});var Et=c(I);Ge=l(Et,"CODE",{});var _n=c(Ge);Po=a(_n,".produce()"),_n.forEach(s),Oo=a(Et," is used to send events to Kafka asynchronously, and "),Fe=l(Et,"CODE",{});var bn=c(Fe);Do=a(bn,".flush()"),bn.forEach(s),Lo=a(Et," is used to make sure all produce requests and callbacks are complete."),Et.forEach(s),Rt=u(t),oe=l(t,"H4",{});var yn=c(oe);Io=a(yn,"methods for transactions"),yn.forEach(s),qt=u(t),h=l(t,"P",{});var O=c(h);Qe=l(O,"CODE",{});var Cn=c(Qe);Ko=a(Cn,"Producer.init_transactions()"),Cn.forEach(s),To=u(O),Ve=l(O,"CODE",{});var wn=c(Ve);go=a(wn,"Producer.begin_transaction()"),wn.forEach(s),zo=u(O),We=l(O,"CODE",{});var Pn=c(We);So=a(Pn,"Producer.commit_transaction()"),Pn.forEach(s),Ro=u(O),Xe=l(O,"CODE",{});var On=c(Xe);qo=a(On,"Producer.abort_transaction()"),On.forEach(s),Ho=u(O),Ye=l(O,"CODE",{});var Dn=c(Ye);xo=a(Dn,"Producer.send_offsets_to_transaction()"),Dn.forEach(s),O.forEach(s),Ht=u(t),ae=l(t,"H3",{});var Ln=c(ae);Mo=a(Ln,"example code"),Ln.forEach(s),xt=u(t),j=l(t,"PRE",{class:!0});var tl=c(j);tl.forEach(s),Mt=u(t),ne=l(t,"H2",{});var In=c(ne);Ao=a(In,"Consumer"),In.forEach(s),At=u(t),H=l(t,"P",{});var $t=c(H);Uo=a($t,"The "),Ze=l($t,"CODE",{});var Kn=c(Ze);No=a(Kn,"Consumer"),Kn.forEach(s),jo=a($t," class\u2019 main function used to read events from the Kafka cluster. It is also responsbile several areas like:"),$t.forEach(s),Ut=u(t),m=l(t,"UL",{});var D=c(m);$e=l(D,"LI",{});var Tn=c($e);Jo=a(Tn,"Subscribing to Kafka topics"),Tn.forEach(s),Bo=u(D),et=l(D,"LI",{});var gn=c(et);Go=a(gn,"Reading from those topics"),gn.forEach(s),Fo=u(D),tt=l(D,"LI",{});var zn=c(tt);Qo=a(zn,"Keeping track of successfully read events (by updating commited offset)"),zn.forEach(s),Vo=u(D),st=l(D,"LI",{});var Sn=c(st);Wo=a(Sn,"Manage offsets of the application"),Sn.forEach(s),Xo=u(D),ot=l(D,"LI",{});var Rn=c(ot);Yo=a(Rn,"Joining Consumer Groups (to horizontally scale the consumer app, up to number of partitions of topic)"),Rn.forEach(s),D.forEach(s),Nt=u(t),le=l(t,"H3",{});var qn=c(le);Zo=a(qn,"configs"),qn.forEach(s),jt=u(t),ce=l(t,"P",{});var Hn=c(ce);$o=a(Hn,"cluster location, security settings, consumer group settings"),Hn.forEach(s),Jt=u(t),E=l(t,"UL",{});var x=c(E);re=l(x,"LI",{});var Ka=c(re);at=l(Ka,"CODE",{});var xn=c(at);ea=a(xn,"group.id"),xn.forEach(s),ta=a(Ka,": the group id that identifies which consumer belongs to which consumer group (i.e. same group id = same consumer group)"),Ka.forEach(s),sa=u(x),y=l(x,"LI",{});var F=c(y);nt=l(F,"CODE",{});var Mn=c(nt);oa=a(Mn,"auto.offset.reset"),Mn.forEach(s),aa=a(F,": whether to start reading at the beginning of topic ("),lt=l(F,"CODE",{});var An=c(lt);na=a(An,"earliest"),An.forEach(s),la=a(F,"), or only read new events as they arrive ("),ct=l(F,"CODE",{});var Un=c(ct);ca=a(Un,"latest"),Un.forEach(s),ra=a(F,"); this only comes into play when there is no offsets in Kafka (e.g. at the start of consumer app or when offset expire)"),F.forEach(s),ia=u(x),ie=l(x,"LI",{});var Ta=c(ie);rt=l(Ta,"CODE",{});var Nn=c(rt);pa=a(Nn,"enable.auto.commit"),Nn.forEach(s),ua=a(Ta,": whether to manually commit offsets using our code, or let the client automatically commit"),Ta.forEach(s),fa=u(x),pe=l(x,"LI",{});var ga=c(pe);it=l(ga,"CODE",{});var jn=c(it);da=a(jn,"isolation.level"),jn.forEach(s),ka=a(ga,": transaction processing, whether to read committed or uncomitted events"),ga.forEach(s),x.forEach(s),Bt=u(t),ue=l(t,"H3",{});var Jn=c(ue);ha=a(Jn,"methods"),Jn.forEach(s),Gt=u(t),J=l(t,"P",{});var za=c(J);pt=l(za,"CODE",{});var Bn=c(pt);ma=a(Bn,"Consumer.subscribe()"),Bn.forEach(s),va=a(za,": subscribes to Kafka topics. can pass in callbacks to handle on reshuffle etc."),za.forEach(s),Ft=u(t),C=l(t,"P",{});var de=c(C);ut=l(de,"CODE",{});var Gn=c(ut);Ea=a(Gn,"Consumer.poll()"),Gn.forEach(s),_a=a(de,": returns either "),ft=l(de,"CODE",{});var Fn=c(ft);ba=a(Fn,"None"),Fn.forEach(s),ya=a(de," or a "),dt=l(de,"CODE",{});var Qn=c(dt);Ca=a(Qn,"Message"),Qn.forEach(s),de.forEach(s),Qt=u(t),fe=l(t,"H3",{});var Vn=c(fe);wa=a(Vn,"example code"),Vn.forEach(s),Vt=u(t),B=l(t,"PRE",{class:!0});var sl=c(B);sl.forEach(s),this.h()},h(){Sa(A,"class","language-py"),Sa(j,"class","language-py"),Sa(B,"class","language-py")},m(t,r){i(t,T,r),e(T,es),i(t,_t,r),i(t,g,r),e(g,ts),e(g,ke),e(ke,ss),e(g,os),i(t,bt,r),i(t,Q,r),e(Q,as),i(t,yt,r),i(t,V,r),e(V,ns),i(t,Ct,r),i(t,d,r),e(d,W),e(W,he),e(he,ls),e(W,cs),e(d,rs),e(d,X),e(X,me),e(me,is),e(X,ps),e(d,us),e(d,Y),e(Y,ve),e(ve,fs),e(Y,ds),e(d,ks),e(d,z),e(z,Ee),e(Ee,hs),e(z,ms),e(z,_e),e(_e,vs),e(z,Es),e(d,_s),e(d,Z),e(Z,be),e(be,bs),e(Z,ys),i(t,wt,r),i(t,$,r),e($,Cs),i(t,Pt,r),i(t,S,r),e(S,ws),e(S,ye),e(ye,Ps),e(S,Os),i(t,Ot,r),i(t,k,r),e(k,Ce),e(Ce,Ds),e(k,Ls),e(k,we),e(we,Is),e(k,Ks),e(k,Pe),e(Pe,Ts),e(k,gs),e(k,Oe),e(Oe,zs),e(k,Ss),e(k,De),e(De,Rs),i(t,Dt,r),i(t,ee,r),e(ee,qs),i(t,Lt,r),i(t,M,r),e(M,Le),e(Le,Hs),e(M,xs),i(t,It,r),i(t,A,r),A.innerHTML=Yn,i(t,Kt,r),i(t,te,r),e(te,Ms),i(t,Tt,r),i(t,f,r),e(f,R),e(R,Ie),e(Ie,As),e(R,Us),e(R,Ke),e(Ke,Ns),e(R,js),e(f,Js),e(f,v),e(v,Te),e(Te,Bs),e(v,Gs),e(v,ge),e(ge,Fs),e(v,Qs),e(v,ze),e(ze,Vs),e(v,Ws),e(v,Se),e(Se,Xs),e(v,Ys),e(f,Zs),e(f,b),e(b,Re),e(Re,$s),e(b,eo),e(b,qe),e(qe,to),e(b,so),e(b,He),e(He,oo),e(b,ao),e(f,no),e(f,U),e(U,xe),e(xe,lo),e(U,co),e(U,Me),e(Me,ro),e(f,io),e(f,N),e(N,Ae),e(Ae,po),e(N,uo),e(N,Ue),e(Ue,fo),e(f,ko),e(f,q),e(q,ho),e(q,Ne),e(Ne,mo),e(q,vo),e(q,je),e(je,Eo),i(t,gt,r),i(t,se,r),e(se,_o),i(t,zt,r),i(t,L,r),e(L,bo),e(L,Je),e(Je,yo),e(L,Co),e(L,Be),e(Be,wo),i(t,St,r),i(t,I,r),e(I,Ge),e(Ge,Po),e(I,Oo),e(I,Fe),e(Fe,Do),e(I,Lo),i(t,Rt,r),i(t,oe,r),e(oe,Io),i(t,qt,r),i(t,h,r),e(h,Qe),e(Qe,Ko),e(h,To),e(h,Ve),e(Ve,go),e(h,zo),e(h,We),e(We,So),e(h,Ro),e(h,Xe),e(Xe,qo),e(h,Ho),e(h,Ye),e(Ye,xo),i(t,Ht,r),i(t,ae,r),e(ae,Mo),i(t,xt,r),i(t,j,r),j.innerHTML=Zn,i(t,Mt,r),i(t,ne,r),e(ne,Ao),i(t,At,r),i(t,H,r),e(H,Uo),e(H,Ze),e(Ze,No),e(H,jo),i(t,Ut,r),i(t,m,r),e(m,$e),e($e,Jo),e(m,Bo),e(m,et),e(et,Go),e(m,Fo),e(m,tt),e(tt,Qo),e(m,Vo),e(m,st),e(st,Wo),e(m,Xo),e(m,ot),e(ot,Yo),i(t,Nt,r),i(t,le,r),e(le,Zo),i(t,jt,r),i(t,ce,r),e(ce,$o),i(t,Jt,r),i(t,E,r),e(E,re),e(re,at),e(at,ea),e(re,ta),e(E,sa),e(E,y),e(y,nt),e(nt,oa),e(y,aa),e(y,lt),e(lt,na),e(y,la),e(y,ct),e(ct,ca),e(y,ra),e(E,ia),e(E,ie),e(ie,rt),e(rt,pa),e(ie,ua),e(E,fa),e(E,pe),e(pe,it),e(it,da),e(pe,ka),i(t,Bt,r),i(t,ue,r),e(ue,ha),i(t,Gt,r),i(t,J,r),e(J,pt),e(pt,ma),e(J,va),i(t,Ft,r),i(t,C,r),e(C,ut),e(ut,Ea),e(C,_a),e(C,ft),e(ft,ba),e(C,ya),e(C,dt),e(dt,Ca),i(t,Qt,r),i(t,fe,r),e(fe,wa),i(t,Vt,r),i(t,B,r),B.innerHTML=$n},p:Ra,i:Ra,o:Ra,d(t){t&&s(T),t&&s(_t),t&&s(g),t&&s(bt),t&&s(Q),t&&s(yt),t&&s(V),t&&s(Ct),t&&s(d),t&&s(wt),t&&s($),t&&s(Pt),t&&s(S),t&&s(Ot),t&&s(k),t&&s(Dt),t&&s(ee),t&&s(Lt),t&&s(M),t&&s(It),t&&s(A),t&&s(Kt),t&&s(te),t&&s(Tt),t&&s(f),t&&s(gt),t&&s(se),t&&s(zt),t&&s(L),t&&s(St),t&&s(I),t&&s(Rt),t&&s(oe),t&&s(qt),t&&s(h),t&&s(Ht),t&&s(ae),t&&s(xt),t&&s(j),t&&s(Mt),t&&s(ne),t&&s(At),t&&s(H),t&&s(Ut),t&&s(m),t&&s(Nt),t&&s(le),t&&s(jt),t&&s(ce),t&&s(Jt),t&&s(E),t&&s(Bt),t&&s(ue),t&&s(Gt),t&&s(J),t&&s(Ft),t&&s(C),t&&s(Qt),t&&s(fe),t&&s(Vt),t&&s(B)}}}const cl={title:"Kafka and Python",date:"2023-03-15"},{title:Wn,date:il}=cl;class pl extends ol{constructor(T){super(),al(this,T,null,ll,nl,{})}}export{pl as default,cl as metadata};
